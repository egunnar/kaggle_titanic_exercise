{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "summary for downloaded/train.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "\n",
      "summary for downloaded/test.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# just quickly explore contents of cell\n",
    "for i in (['downloaded/train.csv', 'downloaded/test.csv']):\n",
    "    print('\\nsummary for {}'.format(i))\n",
    "    df_tmp = pd.read_csv(i)\n",
    "    df_tmp.info()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_preprocessing(df):\n",
    "    ''' Put DataFrame df in a nice format ready for scikit-learn'''\n",
    "    \n",
    "    # Note I don't do feature scaling as not needed for a decision tree but \n",
    "    # may want to add in later\n",
    "    \n",
    "    sex_mapping = {\n",
    "        'female': 0,\n",
    "        'male': 1,\n",
    "    }\n",
    "    df['Sex'] = df['Sex'].map(sex_mapping)\n",
    "    \n",
    "    # for missing Fare put in the mean\n",
    "    imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    print(df['Fare'].values.dtype)\n",
    "    imr = imr.fit(df['Fare'].values.reshape(-1, 1))\n",
    "    imputed_data = imr.transform(df['Fare'].values.reshape(-1,1))\n",
    "    df['Fare'] = pd.DataFrame(imputed_data)\n",
    "    \n",
    "    # for missing Age put in the mean\n",
    "    # Made it worse. Comment out!\n",
    "    # A idea that might be better is fill in the mean based on similiar values.\n",
    "    # For example get the mean per Pclass and Sex and fill in that mean for matching\n",
    "    # Pclass and Sex.\n",
    "    # imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    # print(df['Age'].values.dtype)\n",
    "    # imr = imr.fit(df['Age'].values.reshape(-1, 1))\n",
    "    # imputed_data = imr.transform(df['Age'].values.reshape(-1,1))\n",
    "    # df['Age'] = pd.DataFrame(imputed_data)    \n",
    "    \n",
    "    \n",
    "    # Turn Embarked Q, S, C into binary columns\n",
    "    df['Embarked'] = df['Embarked'].fillna('Missing')\n",
    "    df['Embarked'] = df['Embarked'].map({    \n",
    "        'Q':0,\n",
    "        'S':1,\n",
    "        'C':2,\n",
    "        'Missing':3\n",
    "    })\n",
    "    ohe = OneHotEncoder(categorical_features=[0], n_values = 4)\n",
    "    x = ohe.fit_transform(df['Embarked'].values.reshape(-1, 1)).toarray()\n",
    "    x = pd.DataFrame(x)\n",
    "    x = x.rename(index=str, columns={\n",
    "        0: \"embarked_q\", \n",
    "        1: \"embarked_s\",\n",
    "        2: \"embarked_c\",\n",
    "        3: \"embarked_missing\",\n",
    "    })\n",
    "    x.index = range(len(x))\n",
    "    df.index = range(len(df))\n",
    "    df = df.join(x)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# There are the actual feature that the algorithms uses. Other data points\n",
    "# are ignored for various reasons\n",
    "training_columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', ]\n",
    "\n",
    "df_train_raw = pd.read_csv('downloaded/train.csv')\n",
    "df_train = do_preprocessing(df_train_raw)\n",
    "y_train = df_train['Survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_train[training_columns], \n",
    "    y_train, test_size=0.3, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note using Decision Tree but kept it commented out as it could be a useful.\n",
    "\n",
    "# tree = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=0)\n",
    "# tree.fit(x_train.as_matrix(), y_train.as_matrix())\n",
    "# y_pred = tree.predict(x_test)\n",
    "# Accuracy: 0.806\n",
    "# print('Accuracy for 70/30 split: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.832\n"
     ]
    }
   ],
   "source": [
    "# TODO should try a grid search for the Decision Tree parameters\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Note this score is bogus (too high) as it fit against the \n",
    "forest.fit(x_train.as_matrix(), y_train.as_matrix())\n",
    "y_pred = forest.predict(x_test)\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last step generate the file to send to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# I'm going fit my random forest against everything for the final prediction file for \n",
    "# kaggle. Although there might be some overfitting it may increase the score.\n",
    "x_everything = do_preprocessing(pd.read_csv('downloaded/train.csv'))\n",
    "y_everything = x_everything['Survived']\n",
    "forest.fit(x_everything[training_columns].as_matrix(), y_everything.as_matrix())\n",
    "\n",
    "# Finally do prediction for test.csv\n",
    "df_test_raw = pd.read_csv('downloaded/test.csv')\n",
    "df_test = do_preprocessing(df_test_raw)\n",
    "x_test = df_test[training_columns]\n",
    "result = forest.predict(x_test)\n",
    "\n",
    "# last step is output the results to a csv and get the columns correct\n",
    "df_for_file = df_test[['PassengerId',]]\n",
    "df_result = pd.DataFrame(result)\n",
    "df_result.columns = ['Survived']\n",
    "# get id of false pandas warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "df_for_file['Survived'] = df_result[['Survived',]]\n",
    "df_for_file.to_csv(\"out.csv\", header = ['PassengerId', 'Survived'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
